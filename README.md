# ğŸš€ Web Analytics Backend (Ingestion + Queue + Processor + Reporting)

A high-performance **event analytics backend** built using:

- **Node.js**
- **Redis Queue**
- **MongoDB**
- **Docker Compose**
- **Microservice Architecture**

This project simulates how real analytics platforms (like Mixpanel, Segment, PostHog) collect and process high-volume events **without slowing down clients**.

---

# â­ Features

### ğŸŸ¢ 1. Ultra-fast Ingestion API
- Accepts events in **milliseconds**
- Does **NOT** block on DB writes
- Pushes events into Redis queue asynchronously

### ğŸŸ¡ 2. Background Processor Worker
- Consumes events from Redis  
- Inserts raw events into MongoDB  
- Updates aggregated statistics  
- Tracks unique users  

### ğŸ”µ 3. Reporting / Stats API
Returns aggregated analytics such as:

- total views  
- unique users  
- top paths  

---

# ğŸ§  High-Level Architecture

yaml
Copy code
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Client Website     â”‚
        â”‚  (Sends Events)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   |
                   v
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Ingestion API      â”‚
        â”‚ (Fast, Non-Blocking) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   |
          Redis Queue (events_queue)
                   |
                   v
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Processor Worker   â”‚
        â”‚  (Async Consumer)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   |
                   v
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       MongoDB        â”‚
        â”‚ events / stats/users â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   |
                   v
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Reporting API     â”‚
        â”‚ Returns Aggregations â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
yaml
Copy code

---

# âš™ï¸ Tech Stack

| Component       | Technology |
|----------------|------------|
| APIs           | Node.js, Express |
| Queue          | Redis |
| Worker         | Node.js |
| Database       | MongoDB |
| Containerization | Docker Compose |

---

# ğŸ“ Folder Structure

analytics-project/
â”‚â”€â”€ docker-compose.yml
â”‚â”€â”€ README.md
â”‚
â””â”€â”€ services/
â”œâ”€â”€ ingestion/
â”‚ â”œâ”€â”€ src/index.js
â”‚ â”œâ”€â”€ package.json
â”‚ â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ processor/
â”‚ â”œâ”€â”€ src/worker.js
â”‚ â”œâ”€â”€ package.json
â”‚ â””â”€â”€ Dockerfile
â”‚
â””â”€â”€ reporting/
â”œâ”€â”€ src/index.js
â”œâ”€â”€ package.json
â””â”€â”€ Dockerfile

yaml
Copy code

---

# ğŸ³ Setup & Run Instructions (Docker Only)

## 1ï¸âƒ£ Clone the repo

```bash
git clone https://github.com/Abhinavv-933/analytics-project.git
cd analytics-project
2ï¸âƒ£ Run all services
bash
Copy code
docker compose up --build
This will start:

Redis

MongoDB

Ingestion API â†’ http://localhost:3001

Reporting API â†’ http://localhost:3002

Processor Worker

ğŸ“¡ API Documentation
âœ… POST /event (Ingestion API)
URL:

bash
Copy code
http://localhost:3001/event
Method:
POST

Request Body:

json
Copy code
{
  "site_id": "site-abc-123",
  "event_type": "page_view",
  "path": "/pricing",
  "user_id": "user-xyz-789",
  "timestamp": "2025-11-12T19:30:01Z"
}
Success Response:

json
Copy code
{
  "status": "accepted",
  "event_id": "uuid-value"
}
ğŸ“Š GET /stats (Reporting API)
URL:

bash
Copy code
http://localhost:3002/stats?site_id=site-abc-123&date=2025-11-12
Response Example:

json
Copy code
{
  "site_id": "site-abc-123",
  "date": "2025-11-12",
  "total_views": 1450,
  "unique_users": 212,
  "top_paths": [
    { "path": "/pricing", "views": 700 },
    { "path": "/blog/post-1", "views": 500 },
    { "path": "/", "views": 250 }
  ]
}
ğŸ—„ï¸ Database Schema
ğŸ”¹ Raw Events (events)
json
Copy code
{
  "event_id": "uuid",
  "site_id": "site-abc-123",
  "event_type": "page_view",
  "path": "/pricing",
  "user_id": "user-xyz-789",
  "timestamp": "2025-11-12T19:30:01Z",
  "date": "2025-11-12"
}
ğŸ”¹ Aggregated Stats (stats)
json
Copy code
{
  "site_id": "site-abc-123",
  "date": "2025-11-12",
  "total_views": 1450,
  "paths": {
    "/pricing": 700,
    "/": 250
  }
}
ğŸ”¹ Unique Users (unique_users)
json
Copy code
{
  "site_id": "site-abc-123",
  "date": "2025-11-12",
  "user_id": "user-xyz-789",
  "first_seen": "2025-11-12T19:30:01Z"
}
ğŸ”¥ Why This Architecture?
ğŸŸ© Fast Ingestion
Clients should not wait for database writes.

ğŸŸ¦ Redis Queue
Makes ingestion asynchronous and highly scalable.

ğŸŸ§ Background Worker
Handles heavy tasks:

DB writes

Unique user tracking

Aggregation calculations

ğŸŸ¨ MongoDB
Stores both raw events and optimized aggregated stats.

ğŸš€ Scaling Strategy (Interview-Ready)
Layer	Scaling Method
Ingestion API	Load balancer + multiple replicas
Queue	Move from Redis â†’ Kafka
Processor	Add more worker instances
Database	Sharding or migrate to ClickHouse
Reporting API	Add read replicas

ğŸ‘¨â€ğŸ’» Author
Abhinav
Stack: Node.js, Redis, MongoDB, Docker